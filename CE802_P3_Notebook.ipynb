{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.ensemble import AdaBoostRegressor, RandomForestRegressor\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from itertools import product\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./CE802_P3_Data/CE802_P3_Data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the amount of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check missing null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Target    0\n",
       "F1        0\n",
       "F2        0\n",
       "F3        0\n",
       "F4        0\n",
       "F5        0\n",
       "F6        0\n",
       "F7        0\n",
       "F8        0\n",
       "F9        0\n",
       "F10       0\n",
       "F11       0\n",
       "F12       0\n",
       "F13       0\n",
       "F14       0\n",
       "F15       0\n",
       "F16       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check about the types of the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1500 entries, 0 to 1499\n",
      "Data columns (total 17 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Target  1500 non-null   float64\n",
      " 1   F1      1500 non-null   float64\n",
      " 2   F2      1500 non-null   float64\n",
      " 3   F3      1500 non-null   float64\n",
      " 4   F4      1500 non-null   float64\n",
      " 5   F5      1500 non-null   float64\n",
      " 6   F6      1500 non-null   float64\n",
      " 7   F7      1500 non-null   float64\n",
      " 8   F8      1500 non-null   object \n",
      " 9   F9      1500 non-null   int64  \n",
      " 10  F10     1500 non-null   float64\n",
      " 11  F11     1500 non-null   float64\n",
      " 12  F12     1500 non-null   int64  \n",
      " 13  F13     1500 non-null   float64\n",
      " 14  F14     1500 non-null   float64\n",
      " 15  F15     1500 non-null   object \n",
      " 16  F16     1500 non-null   float64\n",
      "dtypes: float64(13), int64(2), object(2)\n",
      "memory usage: 199.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Europe', 'Rest', 'UK', 'USA'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['F8'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['High', 'Very low', 'Very high', 'Medium', 'Low'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['F15'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the preprocess function\n",
    "\n",
    "This function has the objective of preparing the current dataframe named as `df` by creating dummy variables and mapping categorical values, as well as moving the `Target` column as the first column in the df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess():\n",
    "    global df\n",
    "    df = pd.get_dummies(df, columns=['F8'])\n",
    "    f15_mapping_dict = {'Very low': 0, 'Low': 1, 'Medium': 2, 'High': 3, 'Very high': 4}\n",
    "    df['F15'] = df['F15'].map(f15_mapping_dict)\n",
    "    value = df['Target']\n",
    "    df = df.drop(columns=['Target'])\n",
    "    df.insert(0, 'Target', value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F9</th>\n",
       "      <th>F10</th>\n",
       "      <th>F11</th>\n",
       "      <th>F12</th>\n",
       "      <th>F13</th>\n",
       "      <th>F14</th>\n",
       "      <th>F15</th>\n",
       "      <th>F16</th>\n",
       "      <th>F8_Europe</th>\n",
       "      <th>F8_Rest</th>\n",
       "      <th>F8_UK</th>\n",
       "      <th>F8_USA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>167.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.73</td>\n",
       "      <td>3.14</td>\n",
       "      <td>5.73</td>\n",
       "      <td>-5.48</td>\n",
       "      <td>-743.61</td>\n",
       "      <td>152.20</td>\n",
       "      <td>3</td>\n",
       "      <td>1577.82</td>\n",
       "      <td>-383.82</td>\n",
       "      <td>12</td>\n",
       "      <td>-2289.14</td>\n",
       "      <td>-19.69</td>\n",
       "      <td>3</td>\n",
       "      <td>25354.83</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>704.46</td>\n",
       "      <td>9.84</td>\n",
       "      <td>3.46</td>\n",
       "      <td>6.02</td>\n",
       "      <td>14.42</td>\n",
       "      <td>-10.94</td>\n",
       "      <td>-820.35</td>\n",
       "      <td>68.56</td>\n",
       "      <td>4</td>\n",
       "      <td>1884.69</td>\n",
       "      <td>-488.34</td>\n",
       "      <td>6</td>\n",
       "      <td>-2899.20</td>\n",
       "      <td>-19.46</td>\n",
       "      <td>0</td>\n",
       "      <td>32380.17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>302.43</td>\n",
       "      <td>4.14</td>\n",
       "      <td>-1.95</td>\n",
       "      <td>6.96</td>\n",
       "      <td>4.27</td>\n",
       "      <td>-7.94</td>\n",
       "      <td>-818.43</td>\n",
       "      <td>107.86</td>\n",
       "      <td>4</td>\n",
       "      <td>2063.79</td>\n",
       "      <td>-287.76</td>\n",
       "      <td>6</td>\n",
       "      <td>-2885.52</td>\n",
       "      <td>-20.57</td>\n",
       "      <td>4</td>\n",
       "      <td>28882.38</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2420.98</td>\n",
       "      <td>20.06</td>\n",
       "      <td>-3.34</td>\n",
       "      <td>3.76</td>\n",
       "      <td>4.78</td>\n",
       "      <td>-6.30</td>\n",
       "      <td>-814.53</td>\n",
       "      <td>147.04</td>\n",
       "      <td>7</td>\n",
       "      <td>1319.19</td>\n",
       "      <td>-435.54</td>\n",
       "      <td>4</td>\n",
       "      <td>-2319.80</td>\n",
       "      <td>-20.24</td>\n",
       "      <td>4</td>\n",
       "      <td>28523.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>271.65</td>\n",
       "      <td>63.63</td>\n",
       "      <td>-0.97</td>\n",
       "      <td>11.08</td>\n",
       "      <td>5.66</td>\n",
       "      <td>-9.60</td>\n",
       "      <td>-847.41</td>\n",
       "      <td>99.70</td>\n",
       "      <td>1</td>\n",
       "      <td>1921.14</td>\n",
       "      <td>-246.45</td>\n",
       "      <td>10</td>\n",
       "      <td>-1344.40</td>\n",
       "      <td>-21.90</td>\n",
       "      <td>2</td>\n",
       "      <td>27915.81</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Target     F1    F2     F3     F4     F5      F6      F7  F9      F10  \\\n",
       "0   167.75   0.00  1.73   3.14   5.73  -5.48 -743.61  152.20   3  1577.82   \n",
       "1   704.46   9.84  3.46   6.02  14.42 -10.94 -820.35   68.56   4  1884.69   \n",
       "2   302.43   4.14 -1.95   6.96   4.27  -7.94 -818.43  107.86   4  2063.79   \n",
       "3  2420.98  20.06 -3.34   3.76   4.78  -6.30 -814.53  147.04   7  1319.19   \n",
       "4   271.65  63.63 -0.97  11.08   5.66  -9.60 -847.41   99.70   1  1921.14   \n",
       "\n",
       "      F11  F12      F13    F14  F15       F16  F8_Europe  F8_Rest  F8_UK  \\\n",
       "0 -383.82   12 -2289.14 -19.69    3  25354.83          1        0      0   \n",
       "1 -488.34    6 -2899.20 -19.46    0  32380.17          0        1      0   \n",
       "2 -287.76    6 -2885.52 -20.57    4  28882.38          0        1      0   \n",
       "3 -435.54    4 -2319.80 -20.24    4  28523.04          0        0      1   \n",
       "4 -246.45   10 -1344.40 -21.90    2  27915.81          1        0      0   \n",
       "\n",
       "   F8_USA  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quick analysis of correlation of features and class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_theme()\n",
    "# Compute the correlation matrix\n",
    "corr_all = df.corr()\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr_all, dtype = np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr_all, mask = mask, cmap = \"BuPu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like the maybe the best columns to check will be:\n",
    "\n",
    "- F3\n",
    "- F4\n",
    "- F7\n",
    "- F9\n",
    "- F13\n",
    "- F15\n",
    "- F8_Rest\n",
    "\n",
    "This will help to reduce the complexity but have those variables that seems correlated with the class column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Â Creation of datasets\n",
    "\n",
    "With this function we will prepare the df to have specific columns in the created training and testing datasets, as well as scaling the values of the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_cols = ['F3', 'F4', 'F7', 'F9', 'F13', 'F15', 'F8_Rest']\n",
    "def create_datasets(all_columns=True, cols=None):\n",
    "    x_cols = df.columns[1:] if all_columns else corr_cols if cols is None else cols\n",
    "    X, Y = df[x_cols], df['Target']\n",
    "    scaler = MinMaxScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3)\n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "corr_datasets = lambda: create_datasets(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create function to permurate params\n",
    "What this function will do is the following\n",
    "\n",
    "1. Create all the combination of the possible parameters values given to the function.Ex.\n",
    "\n",
    "`params = [[1, 2], [4, 5]] -> products = [(1, 4), (1, 5), (2, 4), (2, 5)]`\n",
    "\n",
    "2. Evaluate each of the products using the builder function. _Note. All the builders will return a score, in this case the score is the mean accuracy of the model_\n",
    "3. Based on the prior evaluation, we will see which is the argmax and return the score and params used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutate_params(builder, params):\n",
    "    products = list(product(*params))\n",
    "    scores = list(map(builder, products))\n",
    "    max_index = np.argmax(scores)\n",
    "    return scores[max_index], products[max_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This score function is to conveniently get the score for the scikit learn models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(model):\n",
    "    return model.fit(training[0], training[1]).score(testing[0], testing[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get training and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "training, testing = create_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7710127762911145"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_score(LinearRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ada(values):\n",
    "    n_estimators, learning_rate, loss = values\n",
    "    return get_score(AdaBoostRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        learning_rate=learning_rate,\n",
    "        loss=loss,\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_values = [25, 50, 100, 200]\n",
    "learning_rate = [0.25, 0.5, 1, 2]\n",
    "loss = ['linear', 'square', 'exponential']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7180073854989814, (200, 1, 'square'))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permutate_params(build_ada, [estimator_values, learning_rate, loss])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_forest(values):\n",
    "    n_estimators, criterion, max_depth, max_features = values\n",
    "    return get_score(RandomForestRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        criterion=criterion,\n",
    "        max_depth=max_depth,\n",
    "        max_features=max_features\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_values = [25, 50, 100, 200]\n",
    "criterions = ['mse', 'mae']\n",
    "max_depth = [10, 40, 160, None]\n",
    "max_features = ['auto', 'sqrt', 'log2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6824304533331697, (100, 'mse', 40, 'auto'))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permutate_params(build_forest, [estimator_values, criterions, max_depth, max_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks\n",
    "\n",
    "This builder function is the must complicated of all. The overall objective of the builder is to create a function that creates a MLP Neural Network that consists of **3 hidden layers**.\n",
    "\n",
    "The main difference with the other builders is that the parameters received for the builder are actually an array consisting of tuples of parameters. As each of this tuples are the parameters that each of the layers may have, in this case being the amount of units per layer and the activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_nn(values):\n",
    "    model = Sequential()\n",
    "    for index, layer_params in enumerate(values):\n",
    "        units, activation = layer_params\n",
    "        if index == 0:\n",
    "            model.add(Dense(units, activation=activation, input_shape=input_shape))\n",
    "        else:\n",
    "            model.add(Dense(units, activation=activation))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(optimizer='Adam', loss='mse')\n",
    "    model.fit(training[0], training[1], epochs=50, verbose=0)\n",
    "    return r2_score(testing[1], model.predict(testing[0]), multioutput='variance_weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_products = list(product([5, 10, 20, 50], ['tanh', 'relu', 'sigmoid']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params ((20, 'tanh'), (50, 'relu'), (50, 'relu'))\n",
      "Best Score 0.9716288287194671\n"
     ]
    }
   ],
   "source": [
    "inputs_num = training[0].shape[1]\n",
    "input_shape = (inputs_num,)\n",
    "best_params, best_score = [], 0\n",
    "\n",
    "for params in list(product(layer_products, layer_products, layer_products)):\n",
    "    score = build_nn(params)\n",
    "    if score > best_score:\n",
    "        best_params = params\n",
    "        best_score = score\n",
    "\n",
    "print('Best params', best_params)\n",
    "print('Best Score', best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the performance (correlation features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "training, testing = corr_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this we will reuse the same code for obtaining the best score and permutation as above, being the only difference the training and testing datasets used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6518751739405821"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_score(LinearRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.571587543259356, (50, 2, 'square'))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permutate_params(build_ada, [estimator_values, learning_rate, loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6628128381970622, (100, 'mse', 40, 'log2'))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permutate_params(build_forest, [estimator_values, criterions, max_depth, max_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params ((50, 'tanh'), (50, 'relu'), (50, 'relu'))\n",
      "Best Score 0.7278559214049255\n"
     ]
    }
   ],
   "source": [
    "best_params, best_score = [], 0\n",
    "inputs_num = training[0].shape[1]\n",
    "input_shape = (inputs_num,)\n",
    "\n",
    "for params in list(product(layer_products, layer_products, layer_products)):\n",
    "    score = build_nn(params)\n",
    "    if score > best_score:\n",
    "        best_params = params\n",
    "        best_score = score\n",
    "\n",
    "print('Best params', best_params)\n",
    "print('Best Score', best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict test dataset\n",
    "\n",
    "Based on the results above, the best model that we obtained was the SVC model using all the data, the following scripts will be used to predict the class of the test dataset using the mentioned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "training, testing = create_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>F10</th>\n",
       "      <th>F11</th>\n",
       "      <th>F12</th>\n",
       "      <th>F13</th>\n",
       "      <th>F14</th>\n",
       "      <th>F15</th>\n",
       "      <th>F16</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>3.68</td>\n",
       "      <td>1.54</td>\n",
       "      <td>-6.70</td>\n",
       "      <td>-929.34</td>\n",
       "      <td>234.18</td>\n",
       "      <td>USA</td>\n",
       "      <td>2</td>\n",
       "      <td>3391.35</td>\n",
       "      <td>-415.41</td>\n",
       "      <td>6</td>\n",
       "      <td>-1460.14</td>\n",
       "      <td>-20.55</td>\n",
       "      <td>Low</td>\n",
       "      <td>31369.98</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.89</td>\n",
       "      <td>2.97</td>\n",
       "      <td>2.28</td>\n",
       "      <td>1.97</td>\n",
       "      <td>-4.52</td>\n",
       "      <td>-700.62</td>\n",
       "      <td>106.84</td>\n",
       "      <td>Rest</td>\n",
       "      <td>2</td>\n",
       "      <td>3479.19</td>\n",
       "      <td>-320.73</td>\n",
       "      <td>2</td>\n",
       "      <td>-2301.76</td>\n",
       "      <td>-27.90</td>\n",
       "      <td>Low</td>\n",
       "      <td>29173.89</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.37</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>7.14</td>\n",
       "      <td>0.40</td>\n",
       "      <td>-14.26</td>\n",
       "      <td>-796.14</td>\n",
       "      <td>32.30</td>\n",
       "      <td>USA</td>\n",
       "      <td>5</td>\n",
       "      <td>918.93</td>\n",
       "      <td>-379.44</td>\n",
       "      <td>4</td>\n",
       "      <td>-2589.08</td>\n",
       "      <td>-20.52</td>\n",
       "      <td>Very low</td>\n",
       "      <td>17248.26</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.37</td>\n",
       "      <td>0.07</td>\n",
       "      <td>7.18</td>\n",
       "      <td>6.81</td>\n",
       "      <td>-6.14</td>\n",
       "      <td>-801.03</td>\n",
       "      <td>32.92</td>\n",
       "      <td>Europe</td>\n",
       "      <td>2</td>\n",
       "      <td>2657.43</td>\n",
       "      <td>-491.28</td>\n",
       "      <td>6</td>\n",
       "      <td>-1767.44</td>\n",
       "      <td>-25.81</td>\n",
       "      <td>Low</td>\n",
       "      <td>15450.54</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.26</td>\n",
       "      <td>6.16</td>\n",
       "      <td>3.54</td>\n",
       "      <td>1.10</td>\n",
       "      <td>-16.76</td>\n",
       "      <td>-652.08</td>\n",
       "      <td>227.98</td>\n",
       "      <td>Rest</td>\n",
       "      <td>4</td>\n",
       "      <td>2739.96</td>\n",
       "      <td>-378.48</td>\n",
       "      <td>10</td>\n",
       "      <td>-1823.32</td>\n",
       "      <td>-23.11</td>\n",
       "      <td>Very low</td>\n",
       "      <td>35745.03</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     F1    F2    F3    F4     F5      F6      F7      F8  F9      F10     F11  \\\n",
       "0  0.04 -0.21  3.68  1.54  -6.70 -929.34  234.18     USA   2  3391.35 -415.41   \n",
       "1  0.89  2.97  2.28  1.97  -4.52 -700.62  106.84    Rest   2  3479.19 -320.73   \n",
       "2  0.37 -0.17  7.14  0.40 -14.26 -796.14   32.30     USA   5   918.93 -379.44   \n",
       "3  5.37  0.07  7.18  6.81  -6.14 -801.03   32.92  Europe   2  2657.43 -491.28   \n",
       "4  0.26  6.16  3.54  1.10 -16.76 -652.08  227.98    Rest   4  2739.96 -378.48   \n",
       "\n",
       "   F12      F13    F14       F15       F16  Target  \n",
       "0    6 -1460.14 -20.55       Low  31369.98     NaN  \n",
       "1    2 -2301.76 -27.90       Low  29173.89     NaN  \n",
       "2    4 -2589.08 -20.52  Very low  17248.26     NaN  \n",
       "3    6 -1767.44 -25.81       Low  15450.54     NaN  \n",
       "4   10 -1823.32 -23.11  Very low  35745.03     NaN  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./CE802_P3_Data/CE802_P3_Test.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F9</th>\n",
       "      <th>F10</th>\n",
       "      <th>F11</th>\n",
       "      <th>F12</th>\n",
       "      <th>F13</th>\n",
       "      <th>F14</th>\n",
       "      <th>F15</th>\n",
       "      <th>F16</th>\n",
       "      <th>F8_Europe</th>\n",
       "      <th>F8_Rest</th>\n",
       "      <th>F8_UK</th>\n",
       "      <th>F8_USA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>3.68</td>\n",
       "      <td>1.54</td>\n",
       "      <td>-6.70</td>\n",
       "      <td>-929.34</td>\n",
       "      <td>234.18</td>\n",
       "      <td>2</td>\n",
       "      <td>3391.35</td>\n",
       "      <td>-415.41</td>\n",
       "      <td>6</td>\n",
       "      <td>-1460.14</td>\n",
       "      <td>-20.55</td>\n",
       "      <td>1</td>\n",
       "      <td>31369.98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.89</td>\n",
       "      <td>2.97</td>\n",
       "      <td>2.28</td>\n",
       "      <td>1.97</td>\n",
       "      <td>-4.52</td>\n",
       "      <td>-700.62</td>\n",
       "      <td>106.84</td>\n",
       "      <td>2</td>\n",
       "      <td>3479.19</td>\n",
       "      <td>-320.73</td>\n",
       "      <td>2</td>\n",
       "      <td>-2301.76</td>\n",
       "      <td>-27.90</td>\n",
       "      <td>1</td>\n",
       "      <td>29173.89</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.37</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>7.14</td>\n",
       "      <td>0.40</td>\n",
       "      <td>-14.26</td>\n",
       "      <td>-796.14</td>\n",
       "      <td>32.30</td>\n",
       "      <td>5</td>\n",
       "      <td>918.93</td>\n",
       "      <td>-379.44</td>\n",
       "      <td>4</td>\n",
       "      <td>-2589.08</td>\n",
       "      <td>-20.52</td>\n",
       "      <td>0</td>\n",
       "      <td>17248.26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.37</td>\n",
       "      <td>0.07</td>\n",
       "      <td>7.18</td>\n",
       "      <td>6.81</td>\n",
       "      <td>-6.14</td>\n",
       "      <td>-801.03</td>\n",
       "      <td>32.92</td>\n",
       "      <td>2</td>\n",
       "      <td>2657.43</td>\n",
       "      <td>-491.28</td>\n",
       "      <td>6</td>\n",
       "      <td>-1767.44</td>\n",
       "      <td>-25.81</td>\n",
       "      <td>1</td>\n",
       "      <td>15450.54</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.26</td>\n",
       "      <td>6.16</td>\n",
       "      <td>3.54</td>\n",
       "      <td>1.10</td>\n",
       "      <td>-16.76</td>\n",
       "      <td>-652.08</td>\n",
       "      <td>227.98</td>\n",
       "      <td>4</td>\n",
       "      <td>2739.96</td>\n",
       "      <td>-378.48</td>\n",
       "      <td>10</td>\n",
       "      <td>-1823.32</td>\n",
       "      <td>-23.11</td>\n",
       "      <td>0</td>\n",
       "      <td>35745.03</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Target    F1    F2    F3    F4     F5      F6      F7  F9      F10     F11  \\\n",
       "0     NaN  0.04 -0.21  3.68  1.54  -6.70 -929.34  234.18   2  3391.35 -415.41   \n",
       "1     NaN  0.89  2.97  2.28  1.97  -4.52 -700.62  106.84   2  3479.19 -320.73   \n",
       "2     NaN  0.37 -0.17  7.14  0.40 -14.26 -796.14   32.30   5   918.93 -379.44   \n",
       "3     NaN  5.37  0.07  7.18  6.81  -6.14 -801.03   32.92   2  2657.43 -491.28   \n",
       "4     NaN  0.26  6.16  3.54  1.10 -16.76 -652.08  227.98   4  2739.96 -378.48   \n",
       "\n",
       "   F12      F13    F14  F15       F16  F8_Europe  F8_Rest  F8_UK  F8_USA  \n",
       "0    6 -1460.14 -20.55    1  31369.98          0        0      0       1  \n",
       "1    2 -2301.76 -27.90    1  29173.89          0        1      0       0  \n",
       "2    4 -2589.08 -20.52    0  17248.26          0        0      0       1  \n",
       "3    6 -1767.44 -25.81    1  15450.54          1        0      0       0  \n",
       "4   10 -1823.32 -23.11    0  35745.03          0        1      0       0  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copy_df = df.copy()\n",
    "preprocess()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1500 entries, 0 to 1499\n",
      "Data columns (total 19 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   F1         1500 non-null   float64\n",
      " 1   F2         1500 non-null   float64\n",
      " 2   F3         1500 non-null   float64\n",
      " 3   F4         1500 non-null   float64\n",
      " 4   F5         1500 non-null   float64\n",
      " 5   F6         1500 non-null   float64\n",
      " 6   F7         1500 non-null   float64\n",
      " 7   F9         1500 non-null   int64  \n",
      " 8   F10        1500 non-null   float64\n",
      " 9   F11        1500 non-null   float64\n",
      " 10  F12        1500 non-null   int64  \n",
      " 11  F13        1500 non-null   float64\n",
      " 12  F14        1500 non-null   float64\n",
      " 13  F15        1500 non-null   int64  \n",
      " 14  F16        1500 non-null   float64\n",
      " 15  F8_Europe  1500 non-null   uint8  \n",
      " 16  F8_Rest    1500 non-null   uint8  \n",
      " 17  F8_UK      1500 non-null   uint8  \n",
      " 18  F8_USA     1500 non-null   uint8  \n",
      "dtypes: float64(12), int64(3), uint8(4)\n",
      "memory usage: 181.8 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns=['Target'])\n",
    "print(X.info())\n",
    "X = MinMaxScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15f0fe1c0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_num = training[0].shape[1]\n",
    "input_shape = (inputs_num,)\n",
    "model = Sequential([\n",
    "    Dense(20, activation='tanh', input_shape=input_shape),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(1, activation='linear'),\n",
    "])\n",
    "model.compile(optimizer='Adam', loss='mse')\n",
    "model.fit(training[0], training[1], epochs=50, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>F10</th>\n",
       "      <th>F11</th>\n",
       "      <th>F12</th>\n",
       "      <th>F13</th>\n",
       "      <th>F14</th>\n",
       "      <th>F15</th>\n",
       "      <th>F16</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>3.68</td>\n",
       "      <td>1.54</td>\n",
       "      <td>-6.70</td>\n",
       "      <td>-929.34</td>\n",
       "      <td>234.18</td>\n",
       "      <td>USA</td>\n",
       "      <td>2</td>\n",
       "      <td>3391.35</td>\n",
       "      <td>-415.41</td>\n",
       "      <td>6</td>\n",
       "      <td>-1460.14</td>\n",
       "      <td>-20.55</td>\n",
       "      <td>Low</td>\n",
       "      <td>31369.98</td>\n",
       "      <td>435.738495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.89</td>\n",
       "      <td>2.97</td>\n",
       "      <td>2.28</td>\n",
       "      <td>1.97</td>\n",
       "      <td>-4.52</td>\n",
       "      <td>-700.62</td>\n",
       "      <td>106.84</td>\n",
       "      <td>Rest</td>\n",
       "      <td>2</td>\n",
       "      <td>3479.19</td>\n",
       "      <td>-320.73</td>\n",
       "      <td>2</td>\n",
       "      <td>-2301.76</td>\n",
       "      <td>-27.90</td>\n",
       "      <td>Low</td>\n",
       "      <td>29173.89</td>\n",
       "      <td>-53.704132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.37</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>7.14</td>\n",
       "      <td>0.40</td>\n",
       "      <td>-14.26</td>\n",
       "      <td>-796.14</td>\n",
       "      <td>32.30</td>\n",
       "      <td>USA</td>\n",
       "      <td>5</td>\n",
       "      <td>918.93</td>\n",
       "      <td>-379.44</td>\n",
       "      <td>4</td>\n",
       "      <td>-2589.08</td>\n",
       "      <td>-20.52</td>\n",
       "      <td>Very low</td>\n",
       "      <td>17248.26</td>\n",
       "      <td>72.795120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.37</td>\n",
       "      <td>0.07</td>\n",
       "      <td>7.18</td>\n",
       "      <td>6.81</td>\n",
       "      <td>-6.14</td>\n",
       "      <td>-801.03</td>\n",
       "      <td>32.92</td>\n",
       "      <td>Europe</td>\n",
       "      <td>2</td>\n",
       "      <td>2657.43</td>\n",
       "      <td>-491.28</td>\n",
       "      <td>6</td>\n",
       "      <td>-1767.44</td>\n",
       "      <td>-25.81</td>\n",
       "      <td>Low</td>\n",
       "      <td>15450.54</td>\n",
       "      <td>148.129532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.26</td>\n",
       "      <td>6.16</td>\n",
       "      <td>3.54</td>\n",
       "      <td>1.10</td>\n",
       "      <td>-16.76</td>\n",
       "      <td>-652.08</td>\n",
       "      <td>227.98</td>\n",
       "      <td>Rest</td>\n",
       "      <td>4</td>\n",
       "      <td>2739.96</td>\n",
       "      <td>-378.48</td>\n",
       "      <td>10</td>\n",
       "      <td>-1823.32</td>\n",
       "      <td>-23.11</td>\n",
       "      <td>Very low</td>\n",
       "      <td>35745.03</td>\n",
       "      <td>245.783798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     F1    F2    F3    F4     F5      F6      F7      F8  F9      F10     F11  \\\n",
       "0  0.04 -0.21  3.68  1.54  -6.70 -929.34  234.18     USA   2  3391.35 -415.41   \n",
       "1  0.89  2.97  2.28  1.97  -4.52 -700.62  106.84    Rest   2  3479.19 -320.73   \n",
       "2  0.37 -0.17  7.14  0.40 -14.26 -796.14   32.30     USA   5   918.93 -379.44   \n",
       "3  5.37  0.07  7.18  6.81  -6.14 -801.03   32.92  Europe   2  2657.43 -491.28   \n",
       "4  0.26  6.16  3.54  1.10 -16.76 -652.08  227.98    Rest   4  2739.96 -378.48   \n",
       "\n",
       "   F12      F13    F14       F15       F16      Target  \n",
       "0    6 -1460.14 -20.55       Low  31369.98  435.738495  \n",
       "1    2 -2301.76 -27.90       Low  29173.89  -53.704132  \n",
       "2    4 -2589.08 -20.52  Very low  17248.26   72.795120  \n",
       "3    6 -1767.44 -25.81       Low  15450.54  148.129532  \n",
       "4   10 -1823.32 -23.11  Very low  35745.03  245.783798  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copy_df['Target'] = model.predict(X)\n",
    "copy_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_df.to_csv('./CE802_P3_Data/CE802_P3_Test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
